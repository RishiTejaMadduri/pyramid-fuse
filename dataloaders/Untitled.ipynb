{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 21\n",
    "ignore_label = 255\n",
    "root = '/media/rishi/New Volume/VOCtrainval_11-May-2012/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = [0, 0, 0, 128, 0, 0, 0, 128, 0, 128, 128, 0, 0, 0, 128, 128, 0, 128, 0, 128, 128,\n",
    "           128, 128, 128, 64, 0, 0, 192, 0, 0, 64, 128, 0, 192, 128, 0, 64, 0, 128, 192, 0, 128,\n",
    "           64, 128, 128, 192, 128, 128, 0, 64, 0, 128, 64, 0, 0, 192, 0, 128, 192, 0, 0, 64, 128]\n",
    "\n",
    "zero_pad = 256 * 3 - len(palette)\n",
    "for i in range(zero_pad):\n",
    "    palette.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_mask(mask):\n",
    "    # mask: numpy array of the mask\n",
    "    new_mask = Image.fromarray(mask.astype(np.uint8)).convert('P')\n",
    "    new_mask.putpalette(palette)\n",
    "\n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(mode):\n",
    "    assert mode in ['train', 'val', 'test']\n",
    "    items = []\n",
    "    if mode == 'train':\n",
    "        img_path = os.path.join(root, 'VOCdevkit', 'VOC2012', 'JPEGImages')\n",
    "        mask_path = os.path.join(root, 'VOCdevkit', 'VOC2012', 'SegmentationClass')\n",
    "        data_list = [l.strip('\\n') for l in open(os.path.join(\n",
    "            root, 'VOCdevkit', 'VOC2012', 'ImageSets', 'Segmentation','train.txt')).readlines()]\n",
    "        for it in data_list:\n",
    "            item = (os.path.join(img_path, it + '.jpg'), os.path.join(mask_path, it + '.png'))\n",
    "            items.append(item)\n",
    "    elif mode == 'val':\n",
    "        img_path = os.path.join(root, 'VOCdevkit', 'VOC2012', 'JPEGImages')\n",
    "        mask_path = os.path.join(root, 'VOCdevkit', 'VOC2012', 'SegmentationClass')\n",
    "        data_list = [l.strip('\\n') for l in open(os.path.join(\n",
    "            root, 'VOCdevkit', 'VOC2012', 'ImageSets', 'Segmentation', 'val.txt')).readlines()]\n",
    "        for it in data_list:\n",
    "            item = (os.path.join(img_path, it + '.jpg'), os.path.join(mask_path, it + '.png'))\n",
    "            items.append(item)\n",
    "    else:\n",
    "        img_path = os.path.join(root, 'VOCdevkit (test)', 'VOC2012', 'JPEGImages')\n",
    "        data_list = [l.strip('\\n') for l in open(os.path.join(\n",
    "            root, 'VOCdevkit (test)', 'VOC2012', 'ImageSets', 'Segmentation', 'test.txt')).readlines()]\n",
    "        for it in data_list:\n",
    "            items.append((img_path, it))\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOC(data.Dataset):\n",
    "    def __init__(self, mode, joint_transform=None, sliding_crop=None, transform=None, target_transform=None):\n",
    "        self.imgs = make_dataset(mode)\n",
    "        if len(self.imgs) == 0:\n",
    "            raise RuntimeError('Found 0 images, please check the data set')\n",
    "        self.mode = mode\n",
    "        self.joint_transform = joint_transform\n",
    "        self.sliding_crop = sliding_crop\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        print(\"In_dataset\")\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'test':\n",
    "            img_path, img_name = self.imgs[index]\n",
    "            img = Image.open(os.path.join(img_path, img_name + '.jpg')).convert('RGB')\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            return img_name, img\n",
    "\n",
    "        img_path, mask_path = self.imgs[index]\n",
    "        img = np.asarray(Image.open(img_path), dtype=np.float32)\n",
    "        print(img.size)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            mask = np.asarray(Image.open(mask_path), dtype=np.int32)\n",
    "            #mask = Image.fromarray(mask.astype(np.uint8))\n",
    "        else:\n",
    "            mask = Image.open(mask_path)\n",
    "\n",
    "        if self.joint_transform is not None:\n",
    "            img, mask = self.joint_transform(img, mask)\n",
    "\n",
    "        if self.sliding_crop is not None:\n",
    "            img_slices, mask_slices, slices_info = self.sliding_crop(img, mask)\n",
    "            if self.transform is not None:\n",
    "                img_slices = [self.transform(e) for e in img_slices]\n",
    "            if self.target_transform is not None:\n",
    "                mask_slices = [self.target_transform(e) for e in mask_slices]\n",
    "            img, mask = torch.stack(img_slices, 0), torch.stack(mask_slices, 0)\n",
    "            return img, mask, torch.LongTensor(slices_info)\n",
    "        else:\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            if self.target_transform is not None:\n",
    "                mask = self.target_transform(mask)\n",
    "            return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In_dataset\n"
     ]
    }
   ],
   "source": [
    "train_loader = VOC(\"train\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

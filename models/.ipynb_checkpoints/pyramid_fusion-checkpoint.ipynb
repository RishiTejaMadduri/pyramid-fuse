{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "sys.path.append(\"/home/rishi/Projects/Pyramid-fuse/\")\n",
    "sys.setrecursionlimit(10000000)\n",
    "import Utils\n",
    "from Utils.CubePad import CustomPad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unpool(nn.Module):\n",
    "    # Unpool: 2*2 unpooling with zero padding\n",
    "    def __init__(self, num_channels, stride=2):\n",
    "        super(Unpool, self).__init__()\n",
    "\n",
    "        self.num_channels = num_channels\n",
    "        self.stride = stride\n",
    "\n",
    "        # create kernel [1, 0; 0, 0]\n",
    "        # currently not compatible with running on CPU\n",
    "        self.weights = torch.autograd.Variable(\n",
    "            torch.zeros(num_channels, 1, stride, stride))\n",
    "        self.weights[:, :, 0, 0] = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.conv_transpose2d(x, self.weights.cuda(), stride=self.stride, groups=self.num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    # Initialize filters with Gaussian random weights\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.ConvTranspose2d):\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    # Decoder is the base class for all decoders\n",
    "\n",
    "    names = ['pyramid1', 'pyramid2', 'pyramid3', 'pyramid4']\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.layer1 = None\n",
    "        self.layer2 = None\n",
    "        self.layer3 = None\n",
    "        self.layer4 = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPModule(nn.Module):\n",
    "    def __init__(self, features, out_features=1024, sizes=(1, 2, 3, 6)):\n",
    "        super().__init__()\n",
    "        self.stages = []\n",
    "        self.stages = nn.ModuleList([self._make_stage(features, size) for size in sizes])\n",
    "        self.bottleneck = nn.Conv2d(features * (len(sizes) + 1), out_features, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def _make_stage(self, features, size):\n",
    "        prior = nn.AdaptiveAvgPool2d(output_size=(size, size))\n",
    "        conv = nn.Conv2d(features, features, kernel_size=1, bias=False)\n",
    "        return nn.Sequential(prior, conv)\n",
    "\n",
    "    def forward(self, feats):\n",
    "        h, w = feats.size(2), feats.size(3)\n",
    "        priors = [F.upsample(input=stage(feats), size=(h, w), mode='bilinear') for stage in self.stages] + [feats]\n",
    "        bottle = self.bottleneck(torch.cat(priors, 1))\n",
    "        return self.relu(bottle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPUpsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, w = 2 * x.size(2), 2 * x.size(3)\n",
    "        p = F.upsample(input=x, size=(h, w), mode='bilinear')\n",
    "        return self.conv(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, feats, n_classes=18, sizes=(1, 2, 3, 6), psp_size=2048, deep_features_size=1024):\n",
    "        super().__init__()\n",
    "        self.feats = feats\n",
    "        self.psp = PSPModule(psp_size, 1024, sizes)\n",
    "        self.drop_1 = nn.Dropout2d(p=0.3)\n",
    "\n",
    "        self.up_1 = PSPUpsample(1024, 256)\n",
    "        self.up_2 = PSPUpsample(256, 64)\n",
    "        self.up_3 = PSPUpsample(64, 64)\n",
    "\n",
    "        self.drop_2 = nn.Dropout2d(p=0.15)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(64, n_classes, kernel_size=1),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(deep_features_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        f, class_f = self.feats(x) \n",
    "        p = self.psp(f)\n",
    "        p = self.drop_1(p)\n",
    "\n",
    "        p = self.up_1(p)\n",
    "        p = self.drop_2(p)\n",
    "\n",
    "        p = self.up_2(p)\n",
    "        p = self.drop_2(p)\n",
    "\n",
    "        p = self.up_3(p)\n",
    "        p = self.drop_2(p)\n",
    "\n",
    "        auxiliary = F.adaptive_max_pool2d(input=class_f, output_size=(1, 1)).view(-1, class_f.size(1))\n",
    "\n",
    "        return self.final(p), self.classifier(auxiliary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using this\n",
    "class UpProj(Decoder):\n",
    "    # UpProj decoder consists of 4 upproj modules with decreasing number of channels and increasing feature map size\n",
    "\n",
    "    class UpProjModule(nn.Module):\n",
    "        # UpProj module has two branches, with a Unpool at the start and a ReLu at the end\n",
    "        #   upper branch: 5*5 conv -> batchnorm -> ReLU -> 3*3 conv -> batchnorm\n",
    "        #   bottom branch: 5*5 conv -> batchnorm\n",
    "\n",
    "        def __init__(self, in_channels, out_channels=None, padding=None):\n",
    "            super(UpProj.UpProjModule, self).__init__()\n",
    "            if out_channels is None:\n",
    "                out_channels = in_channels//2\n",
    "            self.pad_3 = padding(1)\n",
    "            self.pad_5 = padding(2)\n",
    "\n",
    "            self.unpool = Unpool(in_channels)\n",
    "            self.upper_branch = nn.Sequential(collections.OrderedDict([\n",
    "                ('pad1', CustomPad(self.pad_5)),\n",
    "                ('conv1',      nn.Conv2d(in_channels, out_channels,\n",
    "                                         kernel_size=5, stride=1, padding=0, bias=False)),\n",
    "                ('batchnorm1', nn.BatchNorm2d(out_channels)),\n",
    "                ('relu',      nn.ReLU()),\n",
    "                ('pad2', CustomPad(self.pad_3)),\n",
    "                ('conv2',      nn.Conv2d(out_channels, out_channels,\n",
    "                                         kernel_size=3, stride=1, padding=0, bias=False)),\n",
    "                ('batchnorm2', nn.BatchNorm2d(out_channels)),\n",
    "            ]))\n",
    "            self.bottom_branch = nn.Sequential(collections.OrderedDict([\n",
    "                ('pad', CustomPad(self.pad_5)),\n",
    "                ('conv',      nn.Conv2d(in_channels, out_channels,\n",
    "                                        kernel_size=5, stride=1, padding=0, bias=False)),\n",
    "                ('batchnorm', nn.BatchNorm2d(out_channels)),\n",
    "            ]))\n",
    "            self.relu = nn.ReLU()\n",
    "            s\n",
    "        def forward(self, x):\n",
    "            x = self.unpool(x)\n",
    "            x1 = self.upper_branch(x)\n",
    "            x2 = self.bottom_branch(x)\n",
    "            x = x1 + x2\n",
    "            x = self.relu(x)\n",
    "            return x\n",
    "\n",
    "    def __init__(self, in_channels, padding):\n",
    "        super(UpProj, self).__init__()\n",
    "        self.padding = getattr(Utils.CubePad, padding)\n",
    "        self.layer1 = self.UpProjModule(in_channels   , padding=self.padding)\n",
    "        self.layer2 = self.UpProjModule(in_channels//2, padding=self.padding)\n",
    "        self.layer3 = self.UpProjModule(in_channels//4, padding=self.padding)\n",
    "        self.layer4 = self.UpProjModule(in_channels//8, padding=self.padding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e2c(equirectangular):\n",
    "    cube = Utils.Equirec2Cube.ToCubeTensor(equirectangular.cuda())\n",
    "    return cube\n",
    "\n",
    "def c2e(cube):\n",
    "    equirectangular = Utils.Cube2Equirec.ToEquirecTensor(cube.cuda())\n",
    "    return equirectangular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size_lst, stride=2):\n",
    "        super(PreprocBlock, self).__init__()\n",
    "        assert len(kernel_size_lst) == 4 and out_channels % 4 == 0\n",
    "        self.lst = nn.ModuleList([])\n",
    "\n",
    "        for (h, w) in kernel_size_lst:\n",
    "            padding = (h//2, w//2)\n",
    "            tmp = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels//4, kernel_size=(h,w), stride=stride, padding=padding),\n",
    "                        nn.BatchNorm2d(out_channels//4),\n",
    "                        nn.ReLU(inplace=True)\n",
    "                    )\n",
    "            self.lst.append(tmp)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        for conv in self.lst:\n",
    "            out.append(conv(x))\n",
    "        out = torch.cat(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fusion_ResNet(nn.Module):\n",
    "    _output_size_init = (256, 256)\n",
    "    def __init__(self, bs, layers, output_size=(256, 256), in_channels=3, pretrained=True, padding='ZeroPad'):\n",
    "\n",
    "        if layers not in [18, 34, 50, 101, 152]:\n",
    "            raise RuntimeError(\n",
    "                'Only 18, 34, 50, 101, and 152 layer model are defined for ResNet. Got {}'.format(layers))\n",
    "\n",
    "        super(fusion_ResNet, self).__init__()\n",
    "        self.padding = getattr(Utils.CubePad, padding)\n",
    "        self.pad_7 = self.padding(3)\n",
    "        self.pad_3 = self.padding(1)\n",
    "        try: from . import resnet\n",
    "        except: import resnet\n",
    "        pretrained_model = getattr(resnet, 'resnet%d'%layers)(pretrained=pretrained, padding=padding)\n",
    "\n",
    "        if in_channels == 3:\n",
    "            self.conv1 = pretrained_model._modules['conv1']\n",
    "            self.bn1 = pretrained_model._modules['bn1']\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(\n",
    "                in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(64)\n",
    "            weights_init(self.conv1)\n",
    "            weights_init(self.bn1)\n",
    "\n",
    "        self.output_size = output_size\n",
    "        if output_size == None:\n",
    "            output_size = _output_size_init\n",
    "        else:\n",
    "            assert isinstance(output_size, tuple)\n",
    "        self.relu = pretrained_model._modules['relu']\n",
    "        self.maxpool = pretrained_model._modules['maxpool']\n",
    "        self.layer1 = pretrained_model._modules['layer1']\n",
    "        self.layer2 = pretrained_model._modules['layer2']\n",
    "        self.layer3 = pretrained_model._modules['layer3']\n",
    "        self.layer4 = pretrained_model._modules['layer4']\n",
    "\n",
    "        # clear memory\n",
    "        del pretrained_model\n",
    "\n",
    "        # define number of intermediate channels\n",
    "        if layers <= 34:\n",
    "            num_channels = 512\n",
    "        elif layers >= 50:\n",
    "            num_channels = 2048\n",
    "\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels //\n",
    "                               2, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels//2)\n",
    "\n",
    "        self.conv2.apply(weights_init)\n",
    "        self.bn2.apply(weights_init)\n",
    "        \n",
    "        self.pre1 = PreprocBlock(3, 64, [[3, 9], [5, 11], [5, 7], [7, 7]])\n",
    "        self.pre1.apply(weights_init)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # resnet\n",
    "        x = inputs\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x0 = x\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "\n",
    "        x = self.conv2(x4)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def pre_encoder(self, x):\n",
    "        x = self.conv1(self.pad_7(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(self.pad_3(x))\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def pre_encoder2(self, x):\n",
    "        x = self.pre1(x)\n",
    "        x = self.maxpool(self.pad_3(x))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CETransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CETransform, self).__init__()\n",
    "        equ_h = [512, 128, 64, 32, 16]\n",
    "        cube_h = [256, 64, 32, 16, 8]\n",
    "\n",
    "        self.c2e = dict()\n",
    "        self.e2c = dict()\n",
    "\n",
    "        for h in equ_h:\n",
    "            a = Utils.Equirec2Cube(1, h, h*2, h//2, 90)\n",
    "            self.e2c['(%d,%d)' % (h, h*2)] = a\n",
    "\n",
    "        for h in cube_h:\n",
    "            a = Utils.Cube2Equirec(1, h, h*2, h*4)\n",
    "            self.c2e['(%d)' % (h)] = a\n",
    "\n",
    "    def E2C(self, x):\n",
    "        [bs, c, h, w] = x.shape\n",
    "        key = '(%d,%d)' % (h, w)\n",
    "        assert key in self.e2c\n",
    "        return self.e2c[key].ToCubeTensor(x)\n",
    "\n",
    "    def C2E(self, x):\n",
    "        [bs, c, h, w] = x.shape\n",
    "        key = '(%d)' % (h)\n",
    "        assert key in self.c2e and h == w\n",
    "        return self.c2e[key].ToEquirecTensor(x)\n",
    "\n",
    "    def forward(self, equi, cube):\n",
    "        return self.e2c(equi), self.c2e(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Refine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Refine, self).__init__()\n",
    "        self.refine_1 = nn.Sequential(\n",
    "                        nn.Conv2d(5, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU(inplace=True)\n",
    "                        )\n",
    "        self.refine_2 = nn.Sequential(\n",
    "                        nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        )\n",
    "        self.deconv_1 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, output_padding=0, groups=1, bias=True, dilation=1),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.LeakyReLU(inplace=True),\n",
    "                        )\n",
    "        self.deconv_2 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(192, 32, kernel_size=4, stride=2, padding=1, output_padding=0, groups=1, bias=True, dilation=1),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.LeakyReLU(inplace=True),\n",
    "                        )\n",
    "        self.refine_3 = nn.Sequential(\n",
    "                        nn.Conv2d(96, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(16),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(16, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "                        )\n",
    "        self.bilinear_1 = nn.UpsamplingBilinear2d(size=(256,512))\n",
    "        self.bilinear_2 = nn.UpsamplingBilinear2d(size=(512,1024))\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        out_1 = self.refine_1(x)\n",
    "        out_2 = self.refine_2(out_1)\n",
    "        deconv_out1 = self.deconv_1(out_2)\n",
    "        up_1 = self.bilinear_1(out_2)\n",
    "        deconv_out2 = self.deconv_2(torch.cat((deconv_out1, up_1), dim = 1))\n",
    "        up_2 = self.bilinear_2(out_1)\n",
    "        out_3 = self.refine_3(torch.cat((deconv_out2, up_2), dim = 1))\n",
    "\n",
    "        return out_3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, layers, output_size=None, in_channels=3, pretrained=True):\n",
    "        super(MyModel, self).__init__()\n",
    "        bs = 1\n",
    "#Initializing the models\n",
    "        self.equi_model = fusion_ResNet(\n",
    "            bs, layers, (512, 1024), 3, pretrained, padding='ZeroPad')\n",
    "        self.cube_model = fusion_ResNet(\n",
    "            bs*6, layers, (256, 256), 3, pretrained, padding='SpherePad')\n",
    "\n",
    "#Initializing the refine module\n",
    "        self.refine_model = Refine()\n",
    "\n",
    "        if layers <= 34:\n",
    "            num_channels = 512\n",
    "        elif layers >= 50:\n",
    "            num_channels = 2048\n",
    "            \n",
    "#         self.equi_decoder = PSPNet(self)\n",
    "#Change input to equi_conv3\n",
    "        self.equi_conv3 = nn.Sequential(\n",
    "                nn.Conv2d(num_channels//32, 1, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.UpsamplingBilinear2d(size=(512, 1024))\n",
    "                )\n",
    "#Change input to cube_conv3\n",
    "#         self.cube_decoder = PSPNet(self)\n",
    "        mypad = getattr(Utils.CubePad, 'SpherePad')\n",
    "        self.cube_conv3 = nn.Sequential(\n",
    "                mypad(1),\n",
    "                nn.Conv2d(num_channels//32, 1, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "                nn.UpsamplingBilinear2d(size=(256, 256))\n",
    "                )\n",
    "#Applying weights so probably using pre-trained models.\n",
    "#         self.equi_decoder.apply(weights_init)\n",
    "        self.equi_conv3.apply(weights_init)\n",
    "#         self.cube_decoder.apply(weights_init)\n",
    "        self.cube_conv3.apply(weights_init)\n",
    "\n",
    "#Transformation function going from C2E and E2C\n",
    "        self.ce = CETransform()\n",
    "        \n",
    "        if layers <= 34:\n",
    "            ch_lst = [64, 64, 128, 256, 512, 256, 128, 64, 32]\n",
    "        else:\n",
    "            ch_lst = [64, 256, 512, 1024, 2048, 1024, 512, 256, 128]\n",
    "\n",
    "#Declaring convolution of e2c, c2e and mask - A module list is used to construct a network. \n",
    "        self.conv_e2c = nn.ModuleList([])\n",
    "        self.conv_c2e = nn.ModuleList([])\n",
    "        self.conv_mask = nn.ModuleList([])\n",
    "#A loop to run through ch_list - This is basically convolution.\n",
    "#Preparing the encoder\n",
    "        for i in range(5):\n",
    "            conv_c2e = nn.Sequential(\n",
    "                        nn.Conv2d(ch_lst[i], ch_lst[i], kernel_size=3, padding=1),\n",
    "                        nn.ReLU(inplace=True)\n",
    "                    )\n",
    "            conv_e2c = nn.Sequential(\n",
    "                        nn.Conv2d(ch_lst[i], ch_lst[i], kernel_size=3, padding=1),\n",
    "                        nn.ReLU(inplace=True)\n",
    "                    )\n",
    "            conv_mask = nn.Sequential(\n",
    "                        nn.Conv2d(ch_lst[i]*2, 1, kernel_size=1, padding=0),\n",
    "                        nn.Sigmoid()\n",
    "                    )\n",
    "            self.conv_e2c.append(conv_e2c)\n",
    "            self.conv_c2e.append(conv_c2e)\n",
    "            self.conv_mask.append(conv_mask)\n",
    "\n",
    "\n",
    "\n",
    "        self.grid = Utils.Equirec2Cube(None, 512, 1024, 256, 90).GetGrid()\n",
    "\n",
    "#Forwarard for FCRN\n",
    "    def forward_FCRN_fusion(self, equi, fusion=False):\n",
    "#going from E2C\n",
    "        cube = self.ce.E2C(equi)\n",
    "#Applying the pre-processing block to deal with distortion\n",
    "        feat_equi = self.equi_model.pre_encoder2(equi)\n",
    "#Check this one out\n",
    "        feat_cube = self.cube_model.pre_encoder(cube)\n",
    "#Running the encoder block\n",
    "        for e in range(5):\n",
    "            if fusion:\n",
    "                aaa = self.conv_e2c[e](feat_equi)\n",
    "                tmp_cube = self.ce.E2C(aaa)\n",
    "                tmp_equi = self.conv_c2e[e](self.ce.C2E(feat_cube))\n",
    "                mask_equi = self.conv_mask[e](torch.cat([aaa, tmp_equi], dim=1))\n",
    "                mask_cube = 1 - mask_equi\n",
    "                tmp_cube = tmp_cube.clone() * self.ce.E2C(mask_cube)\n",
    "                tmp_equi = tmp_equi.clone() * mask_equi\n",
    "            else:\n",
    "                tmp_cube = 0\n",
    "                tmp_equi = 0\n",
    "            feat_cube = feat_cube + tmp_cube\n",
    "            feat_equi = feat_equi + tmp_equi\n",
    "            if e < 4:\n",
    "                feat_cube = getattr(self.cube_model, 'layer%d'%(e+1))(feat_cube)\n",
    "                feat_equi = getattr(self.equi_model, 'layer%d'%(e+1))(feat_equi)\n",
    "            else:\n",
    "                feat_cube = self.cube_model.conv2(feat_cube)\n",
    "                feat_equi = self.equi_model.conv2(feat_equi)\n",
    "                feat_cube = self.cube_model.bn2(feat_cube)\n",
    "                feat_equi = self.equi_model.bn2(feat_equi)\n",
    "\n",
    "        feat_equi = PSPNet(feat_equi)\n",
    "        feat_cube = PSPNet(feat_cube)\n",
    "        feat_cube = self.ce.C2E(feat_cube)\n",
    "        feat_cat = torch.cat((feat_equi, feat_cube), dim = 1)\n",
    "        \n",
    "        refine_final = self.refine_model(feat_cat)\n",
    "        \n",
    "        return refine_final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Model = MyModel(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (equi_model): fusion_ResNet(\n",
       "    (pad_7): ZeroPad()\n",
       "    (pad_3): ZeroPad()\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): ZeroPad()\n",
       "      )\n",
       "    )\n",
       "    (conv2): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pre1): PreprocBlock(\n",
       "      (lst): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(3, 16, kernel_size=(3, 9), stride=(2, 2), padding=(1, 4))\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(3, 16, kernel_size=(5, 11), stride=(2, 2), padding=(2, 5))\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(3, 16, kernel_size=(5, 7), stride=(2, 2), padding=(2, 3))\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cube_model): fusion_ResNet(\n",
       "    (pad_7): SpherePad()\n",
       "    (pad_3): SpherePad()\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pad_3): SpherePad()\n",
       "      )\n",
       "    )\n",
       "    (conv2): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pre1): PreprocBlock(\n",
       "      (lst): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(3, 16, kernel_size=(3, 9), stride=(2, 2), padding=(1, 4))\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(3, 16, kernel_size=(5, 11), stride=(2, 2), padding=(2, 5))\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(3, 16, kernel_size=(5, 7), stride=(2, 2), padding=(2, 3))\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (refine_model): Refine(\n",
       "    (refine_1): Sequential(\n",
       "      (0): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU(inplace=True)\n",
       "    )\n",
       "    (refine_2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (deconv_1): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "    (deconv_2): Sequential(\n",
       "      (0): ConvTranspose2d(192, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "    (refine_3): Sequential(\n",
       "      (0): Conv2d(96, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (bilinear_1): UpsamplingBilinear2d(size=(256, 512), mode=bilinear)\n",
       "    (bilinear_2): UpsamplingBilinear2d(size=(512, 1024), mode=bilinear)\n",
       "  )\n",
       "  (equi_conv3): Sequential(\n",
       "    (0): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): UpsamplingBilinear2d(size=(512, 1024), mode=bilinear)\n",
       "  )\n",
       "  (cube_conv3): Sequential(\n",
       "    (0): SpherePad()\n",
       "    (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (2): UpsamplingBilinear2d(size=(256, 256), mode=bilinear)\n",
       "  )\n",
       "  (ce): CETransform()\n",
       "  (conv_e2c): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_c2e): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_mask): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(2048, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(4096, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

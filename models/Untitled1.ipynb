{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1568c6cf4360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Sample.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# import torchvision.models as models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpspnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPSPNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/objloc/code/pyramid-fuse/models/pspnet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitialize_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_trainable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "# sys.path.append(\"/home/rishi/Projects/Pyramid-fuse/\")\n",
    "# # sys.setrecursionlimit(10000000)\n",
    "# import Utils\n",
    "# # from Utils.CubePad import CustomPad\n",
    "image_path = 'Sample.jpg'\n",
    "# import torchvision.models as models\n",
    "from pspnet import PSPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.asarray(Image.open(image_path), dtype=np.float32)\n",
    "img=img.transpose(2,0,1)\n",
    "img=np.expand_dims(img,0)\n",
    "img=torch.tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CETransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CETransform, self).__init__()\n",
    "        equ_h = [512, 128, 64, 32, 16]\n",
    "        cube_h = [256, 64, 32, 16, 8]\n",
    "\n",
    "        self.c2e = dict()\n",
    "        self.e2c = dict()\n",
    "\n",
    "        for h in equ_h:\n",
    "            a = Utils.Equirec2Cube(1, h, h*2, h//2, 90)\n",
    "            self.e2c['(%d,%d)' % (h, h*2)] = a\n",
    "\n",
    "        for h in cube_h:\n",
    "            a = Utils.Cube2Equirec(1, h, h*2, h*4)\n",
    "            self.c2e['(%d)' % (h)] = a\n",
    "\n",
    "    def E2C(self, x):\n",
    "        print(x.shape)\n",
    "        [bs, c, h, w] = x.shape\n",
    "        key = '(%d,%d)' % (h, w)\n",
    "        print(key)\n",
    "        assert key in self.e2c\n",
    "        return self.e2c[key].ToCubeTensor(x)\n",
    "\n",
    "    def C2E(self, x):\n",
    "        print(x.shape)\n",
    "        [bs, c, h, w] = x.shape\n",
    "        key = '(%d)' % (h)\n",
    "        assert key in self.c2e and h == w\n",
    "        return self.c2e[key].ToEquirecTensor(x)\n",
    "\n",
    "    def forward(self, equi, cube):\n",
    "        return self.e2c(equi), self.c2e(cube)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypad = getattr(Utils.CubePad, 'SpherePad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = CETransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = torch.rand((1,3,512,1024)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512, 1024])\n",
      "(512,1024)\n",
      "tensor([[[[0.5428, 0.3148, 0.6410,  ..., 0.6896, 0.7269, 0.0994],\n",
      "          [0.3571, 0.4063, 0.9146,  ..., 0.7948, 0.0436, 0.4228],\n",
      "          [0.2656, 0.1951, 0.4688,  ..., 0.5246, 0.2480, 0.3659],\n",
      "          ...,\n",
      "          [0.2175, 0.3050, 0.5544,  ..., 0.6198, 0.9992, 0.6829],\n",
      "          [0.2661, 0.6307, 0.5076,  ..., 0.5635, 0.9980, 0.1390],\n",
      "          [0.6264, 0.3644, 0.1565,  ..., 0.4353, 0.5788, 0.2921]],\n",
      "\n",
      "         [[0.7930, 0.1298, 0.1656,  ..., 0.3624, 0.8011, 0.4380],\n",
      "          [0.7909, 0.7882, 0.3560,  ..., 0.6038, 0.5465, 0.2286],\n",
      "          [0.8887, 0.0173, 0.8868,  ..., 0.5212, 0.7768, 0.6381],\n",
      "          ...,\n",
      "          [0.3020, 0.5898, 0.7752,  ..., 0.1172, 0.4321, 0.9730],\n",
      "          [0.5912, 0.8841, 0.1362,  ..., 0.6778, 0.1112, 0.3570],\n",
      "          [0.3691, 0.5098, 0.1221,  ..., 0.4269, 0.7718, 0.6942]],\n",
      "\n",
      "         [[0.4914, 0.5273, 0.4225,  ..., 0.0191, 0.7941, 0.3177],\n",
      "          [0.8151, 0.6494, 0.4731,  ..., 0.4635, 0.6747, 0.4139],\n",
      "          [0.2559, 0.9276, 0.8644,  ..., 0.3224, 0.5718, 0.0031],\n",
      "          ...,\n",
      "          [0.1993, 0.1864, 0.7956,  ..., 0.8954, 0.4284, 0.1621],\n",
      "          [0.5078, 0.8961, 0.5724,  ..., 0.0049, 0.2182, 0.9424],\n",
      "          [0.3219, 0.8892, 0.6681,  ..., 0.6678, 0.9555, 0.3683]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[0.5428, 0.3148, 0.6410,  ..., 0.6896, 0.7269, 0.0994],\n",
      "          [0.3571, 0.4063, 0.9146,  ..., 0.7948, 0.0436, 0.4228],\n",
      "          [0.2656, 0.1951, 0.4688,  ..., 0.5246, 0.2480, 0.3659],\n",
      "          ...,\n",
      "          [0.2175, 0.3050, 0.5544,  ..., 0.6198, 0.9992, 0.6829],\n",
      "          [0.2661, 0.6307, 0.5076,  ..., 0.5635, 0.9980, 0.1390],\n",
      "          [0.6264, 0.3644, 0.1565,  ..., 0.4353, 0.5788, 0.2921]],\n",
      "\n",
      "         [[0.7930, 0.1298, 0.1656,  ..., 0.3624, 0.8011, 0.4380],\n",
      "          [0.7909, 0.7882, 0.3560,  ..., 0.6038, 0.5465, 0.2286],\n",
      "          [0.8887, 0.0173, 0.8868,  ..., 0.5212, 0.7768, 0.6381],\n",
      "          ...,\n",
      "          [0.3020, 0.5898, 0.7752,  ..., 0.1172, 0.4321, 0.9730],\n",
      "          [0.5912, 0.8841, 0.1362,  ..., 0.6778, 0.1112, 0.3570],\n",
      "          [0.3691, 0.5098, 0.1221,  ..., 0.4269, 0.7718, 0.6942]],\n",
      "\n",
      "         [[0.4914, 0.5273, 0.4225,  ..., 0.0191, 0.7941, 0.3177],\n",
      "          [0.8151, 0.6494, 0.4731,  ..., 0.4635, 0.6747, 0.4139],\n",
      "          [0.2559, 0.9276, 0.8644,  ..., 0.3224, 0.5718, 0.0031],\n",
      "          ...,\n",
      "          [0.1993, 0.1864, 0.7956,  ..., 0.8954, 0.4284, 0.1621],\n",
      "          [0.5078, 0.8961, 0.5724,  ..., 0.0049, 0.2182, 0.9424],\n",
      "          [0.3219, 0.8892, 0.6681,  ..., 0.6678, 0.9555, 0.3683]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishi/.local/lib/python3.6/site-packages/torch/nn/functional.py:3226: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    }
   ],
   "source": [
    "test = ce.E2C(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "test2 = ce.C2E(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = res(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5645e-24,  3.0872e-41, -1.5645e-24,  3.0872e-41])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
